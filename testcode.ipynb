{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from timm.models.vision_transformer import PatchEmbed, Block\n",
    "\n",
    "# from util.pos_embed import get_2d_sincos_pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import MAEDataset\n",
    "image_path = 'D:/user_data/individual_study/course_work/master-1fa/CS444/project/MAE/mydataset/images'\n",
    "train_path = 'D:/user_data/individual_study/course_work/master-1fa/CS444/project/MAE/mydataset/annotations/trainval.txt'\n",
    "test_path = 'D:/user_data/individual_study/course_work/master-1fa/CS444/project/MAE/mydataset/annotations/test.txt'\n",
    "MAEdataset = MAEDataset(base_image_path = image_path, txt_path=train_path)\n",
    "MAEtestdataset = MAEDataset(base_image_path = image_path, txt_path=test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MAEdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MAEtestdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import PatchEmbed, Block\n",
    "\n",
    "# 定义一些参数\n",
    "img_size = 224  # 输入图像大小\n",
    "patch_size = 16  # 每个 patch 的大小\n",
    "in_chans = 3  # 输入通道数（RGB图像）\n",
    "embed_dim = 1024  # 嵌入维度\n",
    "num_heads = 16  # 注意力头数\n",
    "num_blocks = 6  # Block 数量\n",
    "\n",
    "# 创建输入图像\n",
    "img = torch.randn(2, in_chans, img_size, img_size)  # 输入: batch_size=2, in_chans=3, img_size=224\n",
    "\n",
    "# 使用 PatchEmbed 进行图像嵌入\n",
    "patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "patches = patch_embed(img)  # 形状: (batch_size, num_patches, embed_dim)  (224/16)**2 = 196\n",
    "\n",
    "# 输出 PatchEmbed 的结果维度\n",
    "print(\"PatchEmbed output shape:\", patches.shape)\n",
    "\n",
    "# 创建 Block 示例\n",
    "block = Block(embed_dim, num_heads, mlp_ratio = 4, qkv_bias=True, norm_layer=nn.LayerNorm)\n",
    "\n",
    "# 通过 Block 处理 patches\n",
    "output = block(patches)  # 形状: (batch_size, num_patches, embed_dim)\n",
    "\n",
    "# 输出 Block 的结果维度\n",
    "print(\"Block output shape:\", output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
